{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19661193, 0.10499359, 0.04517666])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tryng my own model with numpy \n",
    "# might try keras later\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import e, inf, sqrt\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# activation \n",
    "def sig(x):\n",
    "    y = 1/(1 + np.exp(-x))\n",
    "    return y\n",
    "\n",
    "# activation gradient\n",
    "def sigDeriv(x):\n",
    "    y = sig(x)*(1-sig(x))\n",
    "    return y\n",
    "x = np.array([1,2,3])\n",
    "sigDeriv(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0          1       1       0       0       0       0       0       0       0   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          1       0       0       0       0       0       0       0       0   \n",
       "3          4       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.read_csv(\"handwritten digits (images).csv\",dtype=int)\n",
    "numOfDatasets = len(dat)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-121.28699186719702"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingData = pd.DataFrame(dat.iloc[:, 1:]).to_numpy(copy=True, dtype=np.int32)\n",
    "\n",
    "# normalise data (make mean 0 and std 1)\n",
    "mean = np.mean(TrainingData)\n",
    "std = np.std(TrainingData)\n",
    "TrainingData = (TrainingData - mean)/std\n",
    "sum(TrainingData[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct ans: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# used to test later \n",
    "def DataColToImage(x):\n",
    "    image = Image.fromarray(TrainingData[x, :].reshape(28,28) * std + mean)\n",
    "    plt.imshow(image)\n",
    "    print(\"correct ans:\", dat.iloc[x, 0])\n",
    "DataColToImage(random.randint(0,42000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingData[1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "# separate training and test data by indexes \n",
    "testNum = 6000\n",
    "allIndex = list(range(0,42000))\n",
    "trainIndex = []\n",
    "for i in range(0, 42000 - testNum):\n",
    "    x = random.randint(0, len(allIndex) - 1)\n",
    "    trainIndex.append(allIndex[x])\n",
    "    allIndex.pop(x)\n",
    "testIndex = allIndex\n",
    "print(len(testIndex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2,3],\n",
    "              [1,2,3]])\n",
    "\n",
    "y = np.array([[1,2,3]])\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 784) (90, 70) (10, 90)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.47893745, 0.39252905, 0.54990216, ..., 0.451808  , 0.6147732 ,\n",
       "        0.59868301],\n",
       "       [0.42590238, 0.60514057, 0.51553452, ..., 0.47548393, 0.47271572,\n",
       "        0.42244137],\n",
       "       [0.46237309, 0.44640199, 0.43430197, ..., 0.45391562, 0.58919387,\n",
       "        0.43472783],\n",
       "       ...,\n",
       "       [0.40494952, 0.61179244, 0.55759505, ..., 0.56561823, 0.61880531,\n",
       "        0.61563317],\n",
       "       [0.42386977, 0.53623979, 0.48580951, ..., 0.61560063, 0.54139931,\n",
       "        0.55411422],\n",
       "       [0.40689139, 0.40241076, 0.39902126, ..., 0.51249937, 0.47279367,\n",
       "        0.60882924]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputNumber = 784\n",
    "Hidden1NeuronCount = 70\n",
    "Hidden2NeuronCount = 90 \n",
    "outputCount = 10\n",
    "learningRate = 0.1\n",
    "\n",
    "# all weights from each row will lead to same neuron of the next layer \n",
    "# all weights from same column will act on same neuron of current layer\n",
    "# first row weights are all weights that lead to first neuron in the next layer, etc\n",
    "# first column weights are all weights that act on first neuron of current layer \n",
    "# weight.T = [all weights that act on first neuron of current layer]\n",
    "#          [all weights that act on second neuron of current layer], etc...\n",
    "# weight = [all weights that lead to first neuron of next layer]\n",
    "#            [all weights that lead to second neuron of next layer], etc... \n",
    "# data will be a single column\n",
    "# next layer calculated will be single column with all neurons (good)\n",
    "# h,g,f,H,G,F == inactivated and activated hidden layers and final layers respectively\n",
    "\n",
    "weights1 = np.random.uniform(-0.5,0.5,(Hidden1NeuronCount, inputNumber))\n",
    "weights2 = np.random.uniform(-0.5,0.5,(Hidden2NeuronCount, Hidden1NeuronCount))\n",
    "weights3 = np.random.uniform(-0.5,0.5,(outputCount, Hidden2NeuronCount))\n",
    "\n",
    "biases1 = np.random.uniform(-0.1,0.1,(Hidden1NeuronCount, 1))\n",
    "biases2 = np.random.uniform(-0.2,0.2,(Hidden2NeuronCount, 1))\n",
    "biases3 = np.random.uniform(-0.3,0.3,(outputCount,1))\n",
    "\n",
    "print(weights1.shape, weights2.shape, weights3.shape)\n",
    "sig(weights1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "def test():\n",
    "    # single test\n",
    "    randomTest = testIndex[random.randint(0, testNum-1)] # only uses testdata for testing dont use data that will be iused in raining \n",
    "    prams = forwardProp(randomTest, weights1, weights2, weights3, biases1, biases2, biases3)\n",
    "    modelAns, hidden1, hidden2, finallayer, UnactivatedHidden1, UnativatedHidden2, UnactivatedFinalLayer, data = prams\n",
    "    ans = finallayer\n",
    "    cost = np.sum((modelAns - finallayer)**2)\n",
    "    DataColToImage(randomTest)\n",
    "    print(\"predicted:\", ans.argmax())\n",
    "    return ans\n",
    "\n",
    "def testMany():\n",
    "    # test a bunch for accuracy calculations \n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "    for i in range(0, testNum):\n",
    "        singleTest = testIndex[i] # only uses testdata for testing dont use data that will be iused in raining\n",
    "        finallayer = forwardProp(singleTest, weights1, weights2, weights3, biases1, biases2, biases3)[3]\n",
    "        ans = softmax(finallayer)\n",
    "        pred = ans.argmax()\n",
    "        corr = int(dat.iloc[singleTest, 0])\n",
    "        if pred == corr:\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "    print(\"accuracy:\", str((correct/(correct + wrong))*100) + \"%\" , flush=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forwardProp(x, weight1, weight2, weight3, bias1, bias2, bias3):\n",
    "    # forward propagation \n",
    "    data = TrainingData[x,:].reshape(inputNumber,1)\n",
    "    \n",
    "    UnactivatedHidden1 = np.dot(weight1, data)\n",
    "    hidden1 = sig(UnactivatedHidden1) + bias1\n",
    "\n",
    "    UnativatedHidden2 = np.dot(weight2, hidden1)\n",
    "    hidden2 = sig(UnativatedHidden2) + bias2\n",
    "\n",
    "    UnactivatedFinalLayer = np.dot(weight3, hidden2)\n",
    "    finalLayer = sig(UnactivatedFinalLayer) + bias3\n",
    "\n",
    "    correctAns = dat.iloc[x,0]\n",
    "    modelAns = np.zeros((1,outputCount)) # create empty array\n",
    "    modelAns[0,correctAns] = 1 # make the correct index become 1 rest remain 0\n",
    "    return [modelAns, hidden1, hidden2, finalLayer, UnactivatedHidden1, UnativatedHidden2, UnactivatedFinalLayer, data]\n",
    "\n",
    "forwardProp(41999, weights1, weights2, weights3, biases1, biases2, biases3)[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17592565],\n",
       "       [ 0.07720206],\n",
       "       [ 0.05654764],\n",
       "       [-0.12135206],\n",
       "       [ 0.22122827],\n",
       "       [-0.22855987],\n",
       "       [-0.11214764],\n",
       "       [ 0.17882296],\n",
       "       [ 0.18140139],\n",
       "       [ 0.14497557]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(([1,2,3],\n",
    "             [1,2,3]))\n",
    "np.sum(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3224303941006375"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimise weights \n",
    "def backProp(params):\n",
    "# h,g,f,H,G,F == inactivated and activated hidden layers and final layers respectively\n",
    "    global weights1, weights2, weights3, biases1, biases2, biases3\n",
    "    modelAns, H, G, F, h, g, f, data = params\n",
    "    modelAns = modelAns.reshape(outputCount,1)\n",
    "    cost = np.mean((modelAns - F)**2)\n",
    "    \n",
    "    \n",
    "    dCdF = -2*(modelAns - F)\n",
    "    dCdf = dCdF * sigDeriv(f)\n",
    "\n",
    "    dCdG = np.sum(dCdf * weights3, 0).reshape(Hidden2NeuronCount,1)\n",
    "\n",
    "    dCostdWeights3 = np.ones_like(weights3) * G.reshape(1, Hidden2NeuronCount) * dCdf\n",
    "    \n",
    "    dGdg = sigDeriv(g)\n",
    "\n",
    "    dCdH = np.sum((dGdg * dCdG) * weights2, 0).reshape(Hidden1NeuronCount,1)\n",
    "\n",
    "    dCostdWeights2 = np.ones_like(weights2) * H.reshape(1, Hidden1NeuronCount) * dCdG * dGdg\n",
    "\n",
    "    dHdh = sigDeriv(h)\n",
    "\n",
    "    dCostdWeights1 = np.ones_like(weights1) * data.reshape(1, inputNumber) * dCdH * dHdh\n",
    "\n",
    "    dCostdBiases3 = dCdF \n",
    "    dCostdBiases2 = dCdG \n",
    "    dCostdBiases1 = dCdH\n",
    "    weights3 -= dCostdWeights3 * learningRate\n",
    "    weights2 -= dCostdWeights2 * learningRate\n",
    "    weights1 -= dCostdWeights1 * learningRate\n",
    "    biases3 -= dCostdBiases3 * learningRate\n",
    "    biases2 -= dCostdBiases2 * learningRate\n",
    "    biases1 -= dCostdBiases1 * learningRate\n",
    "    return cost\n",
    "\n",
    "backProp(forwardProp(3, weights1, weights2, weights3, biases1, biases2, biases3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. cost =  0.001714821880893386\n",
      "1000. cost =  0.000379189184408444\n",
      "2000. cost =  0.03716385047610894\n",
      "3000. cost =  0.0004643026259820125\n",
      "4000. cost =  0.00323683692284218\n",
      "5000. cost =  0.08362380189776973\n",
      "6000. cost =  0.0010223075498311082\n",
      "7000. cost =  0.11960048723175457\n",
      "8000. cost =  0.0027504368903187204\n",
      "9000. cost =  0.00036207205205334906\n",
      "10000. cost =  0.0014825205757569718\n",
      "11000. cost =  0.0009107274699400641\n",
      "12000. cost =  0.0015265451936112623\n",
      "13000. cost =  0.13059505700555674\n",
      "14000. cost =  0.001558417222468824\n",
      "15000. cost =  4.027888233084223e-05\n",
      "16000. cost =  8.114329534584928e-05\n",
      "17000. cost =  0.00022579598393503465\n",
      "18000. cost =  0.0024196710616807816\n",
      "19000. cost =  0.0002157254050423829\n",
      "20000. cost =  0.000859152286918606\n",
      "21000. cost =  0.04446035356657875\n",
      "22000. cost =  0.00041231471180697783\n",
      "23000. cost =  0.002977841667504053\n",
      "24000. cost =  6.299000436005728e-05\n",
      "25000. cost =  0.003953225063111447\n",
      "26000. cost =  0.0011620994991443877\n",
      "27000. cost =  0.0008254579735694652\n",
      "28000. cost =  0.0007536062401477197\n",
      "29000. cost =  0.0002878814979072284\n",
      "30000. cost =  0.0008248560286085854\n",
      "31000. cost =  0.00031672685721140334\n",
      "32000. cost =  0.005367548368933366\n",
      "33000. cost =  0.009002268252105147\n",
      "34000. cost =  8.692694955277125e-05\n",
      "35000. cost =  0.00016421293875279529\n"
     ]
    }
   ],
   "source": [
    "# train of some data \n",
    "for i in range(42000 - testNum):\n",
    "    x = trainIndex[i] # dont train on testdata\n",
    "    cost = backProp(forwardProp(i, weights1, weights2, weights3, biases1, biases2, biases3))\n",
    "    if i%1000 ==0: # every 1000 iteration print cost \n",
    "        print(f\"{i}. cost = \", cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct ans: 6\n",
      "predicted: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.58472413e-02],\n",
       "       [ 5.90237149e-04],\n",
       "       [ 8.62595657e-02],\n",
       "       [-1.07245400e-02],\n",
       "       [ 2.47667017e-03],\n",
       "       [-5.57276636e-03],\n",
       "       [ 1.01882861e+00],\n",
       "       [-9.94745411e-04],\n",
       "       [-1.65612207e-03],\n",
       "       [-2.03781691e-02]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test() # do one to visualise \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 94.38333333333333%\n"
     ]
    }
   ],
   "source": [
    "testMany() # do many for accuracy calculation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
